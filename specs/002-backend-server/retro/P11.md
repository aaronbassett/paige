# Phase 11 Retrospective: User Story 9 — Coaching Pipeline

## What Worked Well
- Parallel agent launches for all 4 coaching agents (coach, reflection, knowledge-gap, dreyfus) — completed simultaneously
- TDD approach caught null-safety bug in pipeline before it reached production
- Session wrap-up tests used `mockImplementation` with `switch(callType)` pattern — much better than single `mockResolvedValue` for multi-agent flows
- Best-effort agent pattern (try/catch per agent, always mark session completed) provides excellent resilience
- Integration tests with real SQLite verified end-to-end data flow (plans → phases → hints, gaps → katas)

## What Didn't Work
- Coaching pipeline test used `mockCallApi.mockResolvedValue(coachResponse)` which returned the same response for ALL callApi calls — broke memory filter step which expected a different response shape
- The `filterResult.relevant_memories` was undefined when mock returned coach response, then `coach.ts` called `.map()` on undefined

## Workarounds & Solutions
- **Null coalescing for memory filter**: Added `?? []` to `relevantMemories = filterResult.relevant_memories ?? []` in pipeline.ts
- **Defensive `.map()` in coach agent**: `(input.relevantMemories ?? []).map(...)` prevents TypeError when memories are undefined
- **MCP lifecycle test update**: Updated `paige_end_session` test from checking `data.status === 'completed'` to checking `data.success === true` after wiring wrap-up pipeline

## Packages & Dependencies
- No new dependencies required — all agent implementations use existing `callApi` from `@anthropic-ai/sdk`

## Patterns & Code
- **Agent module pattern**: Each agent in `coaching/agents/` exports a single function that calls `callApi<ResponseType>()` with specific model tier, system prompt, and response schema
- **Pipeline orchestration**: pipeline.ts follows a numbered step pattern (13 steps) — clear flow from validation through memory retrieval, agent call, storage, broadcast, return
- **Wrap-up best-effort pattern**: Each of 3 agents wrapped in independent try/catch, session always marked completed regardless of agent failures
- **MCP tool coaching.ts**: Separate registration file for coaching tools, registered in server.ts alongside lifecycle/read/ui tools
- **Round-robin kata distribution**: Katas linked to gaps via `createdGapIds[katasGenerated % createdGapIds.length]`

## For Next Time
- Use `mockCallApi.mockImplementation()` with `switch(options.callType)` for any test that exercises multiple agent calls — avoids returning wrong response shape
- Consider adding a memory filter schema test that validates the Haiku response separately
